---
title: "Support Vector Machine Vorhersage für den 01.01.2019"
output: html_notebook
---
Erstellt am 20.01.2020
Von Tobias Lindenau

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width = 15, fig.height = 10)
```

Pakete installieren
```{r}
#install.packages("dataPreparation")
#install.packages("e1071")
#install.packages("ISLR")
#install.packages("timeDate")

# Importing Function Packages

library(dataPreparation)
library(readr)
library(dplyr)
library(lubridate)
library(broom)
library(ggplot2)
library(timeDate)
library(Metrics)
library(e1071)
library(knitr)

```

Einlesen der Daten
```{r}
# master df einlesen
master_df <- read.csv("master_df.csv")

master_df$Datum <- as.Date(master_df$Datum, format = "%Y-%m-%d")

#X Spalte loeschen
master_df$X<-NULL

```


NA Werte in 0 umwandeln
```{r}
master_df[is.na(master_df)] <- 0
```


Trainings- und Testdatensatz erzeugen. Vorbereitungen
```{r}
set.seed(123)
samples <- sample.int(n = nrow(master_df), size = floor(0.8*nrow(master_df)), replace = FALSE)
train <- master_df[samples, ]
test <- master_df[-samples,]
```


```{r}
#library(ISLR)
#attach(master_df)
#smp_siz = floor(0.75*nrow(master_df))  # creates a value for dividing the data into train and test. In this case the value is defined as 75% of the number of rows in the dataset
#smp_siz  # shows the value of the sample size

#samples <- sample.int(n = nrow(master_df), size = floor(0.7*nrow(master_df)), replace = FALSE)
#train <- master_df[samples, ]
#validation <- master_df[-samples,]
```

Trainings- und Testdatensatz erzeugen.
```{r}
#set.seed(123)   # set seed to ensure you always have same random numbers generated

#train_ind = sample(seq_len(nrow(master_df)),size = smp_siz)  # Randomly identifies therows equal to sample size ( defined in previous instruction) from  all the rows of master_df dataset and stores the row number in train_ind

#train =master_df[train_ind,] #creates the training dataset with row numbers stored in train_ind

#test=master_df[-train_ind,]  # creates the test dataset excluding the row numbers mentioned in train_ind
```

Trainings- und Testdatensatz speichern
```{r}
write.csv (train, file = "train.csv")
write.csv (test, file = "test.csv")

```

2.2 Filter useless variables

The first thing to do, in order to make computation fast, would be to filter useless variables:

    Constant variables
    Variables that are in double (for example col1 == col2)
    Variables that are exact bijections (for example col1 = A, B, B, A and col2 = 1, 2, 2, 1)

Let’s id them:
constant_cols <- whichAreConstant(adult)

# [1] "whichAreConstant: it took me 0s to identify 0 constant column(s)"

double_cols <- whichAreInDouble(adult)

# [1] "whichAreInDouble: it took me 0s to identify 0 column(s) to drop."

bijections_cols <- whichAreBijection(adult)

# [1] "whichAreBijection: education_num is a bijection of education. I put it in drop list."
# [1] "whichAreBijection: it took me 0.05s to identify 1 column(s) to drop."

#We only found, one bijection: variable education_num which is an index for variable education. Let’s drop it:

X_train$education_num = NULL
X_test$education_num = NULL

```{r}
#################
# Data Preparation

# Option to check the correctnes of the code with a small (and computationally fast) training data set
# Do not run or uncomment the following line if you want to reduce the dataset size
###train <- sample_frac(train, .10)
```

### Model vorbereiten

```{r}
mod1 <- lm(Gesamtumsatz ~ Ware_1, train)
mod2 <- lm(Gesamtumsatz ~ Ware_1 + Ware_2 + Ware_3 + Ware_4 + Ware_5 + Ware_6, train)
mod3 <- lm(Gesamtumsatz ~ Ware_1 + Ware_2 + Ware_3 + Ware_4 + Ware_5 + Ware_6 + as.factor(Wochentag), train)
mod4 <- lm(Gesamtumsatz ~ Ware_1 + Ware_2 + Ware_3 + Ware_4 + Ware_5 + Ware_6 + as.factor(Wochentag) + as.factor(Wettercode), train)
mod5 <- lm(Gesamtumsatz ~ Ware_1 + Ware_2 + Ware_3 + Ware_4 + Ware_5 + Ware_6 + as.factor(Wochentag) + as.factor(Wettercode) + Temperaturklassen, train)
mod6 <- lm(Gesamtumsatz ~ Ware_1 + Ware_2 + Ware_3 + Ware_4 + Ware_5 + Ware_6 + as.factor(Wochentag) + as.factor(Wettercode) + Temperaturklassen + nach_feiertag + Ferien + Weihnachtsmarkt, train)
mod7 <- lm(Gesamtumsatz ~ Ware_3 + Ware_5 + Ware_6 + as.factor(Wochentag), train)

summary(mod3)

model_result <- rbind(glance(mod1), glance(mod2), glance(mod3), glance(mod4), glance(mod5), glance(mod6), glance(mod7))

rmse_models <- rbind(rmse(train$Gesamtumsatz, predict(mod1)),
                     rmse(train$Gesamtumsatz, predict(mod2)),
                     rmse(train$Gesamtumsatz, predict(mod3)), #214.3274 bestes Model
                     rmse(train$Gesamtumsatz, predict(mod4)),
                     rmse(train$Gesamtumsatz, predict(mod5)),
                     rmse(train$Gesamtumsatz, predict(mod6)),
                     rmse(train$Gesamtumsatz, predict(mod7))) 

rmse_models_test <- rbind(rmse(test$Gesamtumsatz, predict(mod1, newdata = test)),
                          rmse(test$Gesamtumsatz, predict(mod2, newdata = test)),
                          rmse(test$Gesamtumsatz, predict(mod3, newdata = test)),
                          rmse(test$Gesamtumsatz, predict(mod7, newdata = test))) # bestes Model mit 240.0464


mod1_pred <- predict(mod1, newdata = test)
mod2_pred <- predict(mod2, newdata = test)
mod3_pred <- predict(mod3, newdata = test)
mod7_pred <- predict(mod7, newdata = test)

scatter_input_lm <- validation %>%
  select(Sales, wochentag) %>%
  mutate(mod1 = mod1_pred,
         mod2 = mod2_pred,
         mod3 = mod3_pred,
         mod4 = mod4_pred)
```


### model_svm ###
```{r}
#################
# Training the SVM

# Estimation of an SVM with optimized weighting parameters and given standard hyper parameters
# Typically not used; instead, the function svm_tune is used in order to also get a model with optimized hyper parameters
model_svm <- svm(Gesamtumsatz ~ Ware_1 + Ware_2 + Ware_3 + Ware_4 + Ware_5 + Ware_6 + as.factor(Wochentag), train)

print(model_svm)
summary(model_svm)

```

# estimate model and predict input values
#Beispiel
#m   <- svm(x, y)
#new <- predict(m, x)

### Vorhersage Qualität checken ###
```{r}
# test with train data
pred_train_model_svm <- predict(model_svm, train)

View(pred_train_model_svm)

# compute decision values and probabilites
#pred_train_model_svm <- predict(model_svm, Gesamtumsatz)
#attr(pred, "decision.values")[1:4,]
#attr(pred, "probabilities")[1:4,]

```



### SVM_TUNE ###
```{r}
# Estimation of various SVM (each with optimized weighting parameters) using systematically varied hyper parameters (typically called 'grid search' approach) and cross validation
# the resulting object includes the optimal model in the element named 'best.model'
#Beispiel: svm_tune <- tune(svm, price ~ bedrooms + bathrooms + sqft_living + zipcode, data=house_pricing_train, ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3)))
svm_tune <- tune(svm, Gesamtumsatz ~ Ware_3 + Ware_5 + Ware_6 + as.factor(Wochentag), data=train, ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3)))

print(svm_tune)
summary(svm_tune)
```

## beobachteten und modellierten Umsatz der SVM_Tune vergleichen ##
```{r}
pred_train <- predict(svm_tune$best.model, newdata = test)

rmse_svm <- rmse(test$Gesamtumsatz, pred_train)

scatter_input <- test %>%
  select(Gesamtumsatz) %>%
  mutate(pred_Umsatz = rmse_svm)

scatter_input <- scatter_input %>%
  mutate(pred_Umsatz = rmse_svm)

ggplot(data = scatter_input, aes(x=Gesamtumsatz, y = pred_Umsatz))+
  geom_point()+
  geom_abline(slope = 1, intercept = 0)+
  scale_x_continuous(limits = c(500, 3050))+
  scale_y_continuous(limits = c(500, 3050))+
  labs(title = "Vergleich des beobachteten und des modellierten Umsatzes",
       caption = "basierend auf dem Testdatensatz") +
  xlab("Beobachteter Umsatz")+
  ylab("Vorhergesagter Umsatz")+
  theme(text = element_text(size = 20))

```


```{r}
#################
# Checking the prediction Quality

# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(svm_tune$best.model, train)

# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(svm_tune$best.model, test)

# Calculating the prediction quality for the training data using the MAPE
mape(train$Gesamtumsatz, pred_train)

# Calculating the prediction quality for the training data using the MAPE
mape(test$Gesamtumsatz, pred_test)
```


```{r}
predict()
```

```{r}

```

